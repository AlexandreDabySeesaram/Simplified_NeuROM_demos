[
  {
    "objectID": "demos/1D_element_based.html",
    "href": "demos/1D_element_based.html",
    "title": "Element based 1D HideNN-FEM - ADAM training",
    "section": "",
    "text": "\\(\\forall v\\in V(\\Omega),\\) find \\(u\\in H(\\Omega)\\),\n\\[\\int_\\Omega \\nabla v \\cdot \\lambda(x) \\nabla u = \\int_\\Omega f v  + \\int_{\\partial \\Omega_N} g v\\]\nCode\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport plotly.io as pio\npio.renderers.default = \"notebook\"\ntorch.set_default_dtype(torch.float32)",
    "crumbs": [
      "{{< iconify fa6-solid:rocket width=17 title=HAL >}}",
      "1D NeuROM",
      "Adam"
    ]
  },
  {
    "objectID": "demos/1D_element_based.html#space-interpolation-legacy",
    "href": "demos/1D_element_based.html#space-interpolation-legacy",
    "title": "Element based 1D HideNN-FEM - ADAM training",
    "section": "Space interpolation (legacy)",
    "text": "Space interpolation (legacy)\nWe recode 1D shape functions in HideNN-FEM (first order).\n\n\nCode\nclass mySF1D_elementBased(nn.Module):    \n    def __init__(self, left = -1.,  right = 1.):\n        super().__init__()        \n        \n        self.left   = left\n        self.right  = right\n\n        # To easily transfer to CUDA or change dtype of whole model\n        self.register_buffer('one', torch.tensor([1], dtype=torch.float32))\n\n    def forward(self, x=None, training=False):  \n        if training : x = (self.left + self.right) / torch.tensor(2., requires_grad=True) \n        sf1 = - (x - self.left) / (self.right - self.left) + self.one\n        sf2 = (x - self.left)/(self.right - self.left)\n        if training : return  sf1, sf2, self.right - self.left, x\n        else : return  sf1, sf2\n\n\nl, r    =  -0.9, 0.3\nmySF    = mySF1D_elementBased(left = l, right = r)\n\nXX      = torch.linspace(l,r,100)\ns1, s2  = mySF(XX)\n# plt.plot(XX.data, s1.data,label='N1')\n# plt.plot(XX.data, s2.data,label='N2')\n# plt.grid()\n# plt.xlabel(\"x [mm]\")\n# plt.ylabel(\"shape functions\")\n# plt.legend()  \n# plt.show()\n\n\n\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=XX.data, y=s1.data, name='N1',    line=dict(color='#01426a')))\n\nfig.add_trace(go.Scatter(x=XX.data, y=s2.data, name='N2', line=dict(color='#CE0037')))\n\nfig.update_layout(\n    margin=dict(l=0, r=0, t=0, b=0),\n    plot_bgcolor='rgba(0,0,0,0)',  # Remove background color\n    width=700, \n    height=400,  \n    xaxis=dict(title='x [mm]',\n    showgrid=True,\n    gridcolor='lightgray'),\n    yaxis=dict(title='u(x) [mm]',\n    showgrid=True,\n    gridcolor='lightgray',\n    titlefont=dict(color='#01426a'),\n    tickfont=dict(color='#01426a'),),    \n    legend=dict(x=0, y=1, traceorder=\"normal\")\n)\n\nfig.show()",
    "crumbs": [
      "{{< iconify fa6-solid:rocket width=17 title=HAL >}}",
      "1D NeuROM",
      "Adam"
    ]
  },
  {
    "objectID": "demos/1D_element_based.html#vectorised-version-of-the-element-based-implementation",
    "href": "demos/1D_element_based.html#vectorised-version-of-the-element-based-implementation",
    "title": "Element based 1D HideNN-FEM - ADAM training",
    "section": "Vectorised version of the Element-based implementation",
    "text": "Vectorised version of the Element-based implementation\nWe recode 1D shape functions in HideNN-FEM (first order).\nA vectorised implementation enables batch processing of several points evaluation which in terns enables batch wise differentiation.\n\nIn non-batched implementation\n\ndu_dx = [torch.autograd.grad(u[i], x[i], grad_outputs=torch.ones_like(u[i]), create_graph=True) for i,_ in enumerate(u)\n\nWith the batched version\n\ndu_dx = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)\n\n\n\n\nCode\nclass mySF1D_elementBased_vectorised(nn.Module):\n    def __init__(self, connectivity):\n        super(mySF1D_elementBased_vectorised, self).__init__()\n        if connectivity.dim == 1:\n            connectivity = connectivity[:,None]\n        self.connectivity = connectivity\n        self.register_buffer('GaussPoint',self.GP())\n        self.register_buffer('w_g',torch.tensor(1.0))\n\n\n    def UpdateConnectivity(self,connectivity):\n        self.connectivity = connectivity.astype(int)\n\n    def GP(self):\n        \"Defines the position of the intergration point(s) for the given element\"\n\n        return torch.tensor([[1/2, 1/2]], requires_grad=True)                                       # a1, a2, th 2 area coordinates\n\n    def forward(self, \n                x               : torch.Tensor  = None  , \n                cell_id         : list          = None  , \n                coordinates     : torch.Tensor  = None  , \n                flag_training   : bool          = False):\n\n        assert coordinates is not None, \"No nodes coordinates provided. Aborting\"\n\n        cell_nodes_IDs  = self.connectivity[cell_id,:].T\n        Ids             = torch.as_tensor(cell_nodes_IDs).to(coordinates.device).t()[:,:,None]      # :,:,None] usefull only in 2+D  \n        nodes_coord     = torch.gather(coordinates[:,None,:].repeat(1,2,1),0, Ids.repeat(1,1,1))    # [:,:,None] usefull only in 2+D  Ids.repeat(1,1,d) with d \\in [1,3]\n        \n        nodes_coord = nodes_coord.to(self.GaussPoint.dtype)\n\n        if flag_training:\n            refCoordg   = self.GaussPoint.repeat(cell_id.shape[0],1)\n            Ng          = refCoordg\n            x_g         = torch.einsum('enx,en-&gt;ex',nodes_coord,Ng)\n            refCoord    = self.GetRefCoord(x_g,nodes_coord)\n            N           = refCoord\n            detJ        = nodes_coord[:,1] - nodes_coord[:,0]\n            return N, x_g, detJ*self.w_g\n\n        else:\n            refCoord = self.GetRefCoord(x,nodes_coord)\n            N = torch.stack((refCoord[:,0], refCoord[:,1]),dim=1) \n            return N\n\n    \n    def GetRefCoord(self,x, nodes_coord):\n        InverseMapping          = torch.ones([int(nodes_coord.shape[0]), 2, 2], dtype=x.dtype, device=x.device)\n        detJ                    = nodes_coord[:,0,0] - nodes_coord[:,1,0]\n        InverseMapping[:,0,1]   = -nodes_coord[:,1,0]\n        InverseMapping[:,1,1]   = nodes_coord[:,0,0]\n        InverseMapping[:,1,0]   = -1*InverseMapping[:,1,0]\n        InverseMapping[:,:,:]  /= detJ[:,None,None]\n        x_extended = torch.stack((x, torch.ones_like(x)),dim=1)\n\n\n        return torch.einsum('eij,ej...-&gt;ei',InverseMapping,x_extended.squeeze(1))\n\n\n\nRecall on the iso-parametric Finite Element Method\nIn 1D, for P1 elements, there are two shape functions per element, \\(N_1\\left(\\xi\\right)\\) and \\(N_2\\left(\\xi\\right)\\), \\(\\xi \\in \\left[0,1\\right]\\) being the coordinate in the reference element space.\nThe iso-parametric idea relies on using the same interpolation for the space coordinates as is used for the QoIs, which means that space is interpolated using the same shape functions as the displacement is for instance. Thus, the real space coordinate \\(x\\) satisfies * \\(x = \\sum_{i=1}^{2}N_i\\left(\\xi \\right) x_i\\),\nwith \\(x_i\\) the coordinate of the node associated with the \\(i-\\)th shape function.\nSuch mapping can be expressed using the area coordinates \\(a_1\\) and \\(a_2\\) (such that \\(N_1\\left(\\xi\\right) = a_1\\) and \\(N_2\\left(\\xi\\right) = a_2\\)).\n\\(\\begin{pmatrix}\nx \\\\\n1\n\\end{pmatrix} = \\underbrace{\\begin{bmatrix}\nx_1 & x_2\\\\\n1 & 1\n\\end{bmatrix}}_{\\mathcal{M}} \\begin{pmatrix}\na_1 \\\\\na_2\n\\end{pmatrix}.\\)\nReciprocally (for non degenerated elements),\n\\(\\begin{pmatrix}\na_1 \\\\\na_2\n\\end{pmatrix} = \\underbrace{\\frac{1}{x_1 - x_2}\\begin{bmatrix}\n1 & -x_2\\\\\n-1 & x_1\n\\end{bmatrix}}_{\\mathcal{M}^{-1}} \\begin{pmatrix}\nx \\\\\n1\n\\end{pmatrix}.\\)",
    "crumbs": [
      "{{< iconify fa6-solid:rocket width=17 title=HAL >}}",
      "1D NeuROM",
      "Adam"
    ]
  },
  {
    "objectID": "demos/1D_element_based.html#mesh-generation",
    "href": "demos/1D_element_based.html#mesh-generation",
    "title": "Element based 1D HideNN-FEM - ADAM training",
    "section": "Mesh generation",
    "text": "Mesh generation\n\n\nCode\nN           = 40\nnodes       = torch.linspace(0,6.28,N)\nnodes       = nodes[:,None]\nelements    = torch.vstack([torch.arange(0,N-1),torch.arange(1,N)]).T",
    "crumbs": [
      "{{< iconify fa6-solid:rocket width=17 title=HAL >}}",
      "1D NeuROM",
      "Adam"
    ]
  },
  {
    "objectID": "demos/1D_element_based.html#assembly-using-the-vectorised-element-block",
    "href": "demos/1D_element_based.html#assembly-using-the-vectorised-element-block",
    "title": "Element based 1D HideNN-FEM - ADAM training",
    "section": "Assembly using the vectorised element block",
    "text": "Assembly using the vectorised element block\n\n\nCode\nclass interpolation1D(nn.Module):    \n    def __init__(self, \n            nodes           : torch.Tensor  = None  , \n            elements        : list          = None  , \n            dirichlet       : list          =[0,nodes.shape[0]-1]     ,                 # Fixed nodes (by default, 2 extremities of the beam)\n            n_components    : int           = 1     ):                                  # Number of dofs per node \n        super().__init__()        \n        self.register_buffer('nodes', nodes)\n        self.coordinates =nn.ParameterDict({\n                                    'all': self.nodes,\n                                    })                                                  # Should use different entries for trainable and fixed coordinates\n\n        \n        self.coordinates[\"all\"].requires_grad   = False \n        self.n_components                       = n_components\n        self.register_buffer('values',0.5*torch.ones((self.coordinates[\"all\"].shape[0], self.n_components)))\n        self.dirichlet = dirichlet\n\n        \n        self.elements = elements\n\n        self.Ne = len(elements)\n\n        self.shape_functions = mySF1D_elementBased_vectorised(elements)                 \n\n        # To easily transfer to CUDA or change dtype of whole model\n        self.register_buffer('one', torch.tensor([1], dtype=torch.float32))\n\n        self.SetBCs()\n\n    def SetBCs(self):\n        assert self.n_components == 1, \"only scalar field implemented. Aborting\"\n        if self.n_components == 1:\n            self.dofs_free                  = (torch.ones_like(self.values[:])==1)[:,0]\n            self.dofs_free[self.dirichlet]  = False\n            \n\n\n            nodal_values_imposed            = 0*self.values[~self.dofs_free,:]              # Not generic yet, only 0 BCs\n\n\n            nodal_values_free               = self.values[self.dofs_free,:] \n            self.nodal_values               = nn.ParameterDict({\n                                                'free'      : nodal_values_free,\n                                                'imposed'   : nodal_values_imposed,\n                                                })\n            self.nodal_values['imposed'].requires_grad = False\n\n    def forward(self, x = None): \n        if self.training :\n            k_elt = torch.arange(0,self.Ne)\n        else :\n            k_elt = []\n            for xx in x:\n                for k in range(self.Ne):\n                    elt = self.elements[k]\n                    if xx &gt;= self.coordinates[\"all\"][elt[0]] and xx &lt;= self.coordinates[\"all\"][elt[1]]:\n                        k_elt.append(k)\n                        break\n        if self.training : \n            shape_functions, x_g, detJ = self.shape_functions(\n                x               = x                 , \n                cell_id         = k_elt             , \n                coordinates     = self.nodes        , \n                flag_training   = self.training     )\n        else:\n            shape_functions = self.shape_functions(\n                x               = x                 , \n                cell_id         = k_elt             , \n                coordinates     = self.nodes        , \n                flag_training   = self.training     )\n        # Batch interpolation of the solution using the computed shape functions batch\n        nodal_values_tensor                     = torch.ones_like(self.values)\n        nodal_values_tensor[self.dofs_free,:]   = self.nodal_values['free']\n        nodal_values_tensor[~self.dofs_free,:]  = self.nodal_values['imposed']                    \n\n        cell_nodes_IDs      = self.elements[k_elt,:].T\n        Ids                 = torch.as_tensor(cell_nodes_IDs).to(nodal_values_tensor.device).t()[:,:,None]      # :,:,None] usefull only in 2+D  \n\n        \n        self.nodes_values   = torch.gather(nodal_values_tensor[:,None,:].repeat(1,2,1),0, Ids.repeat(1,1,1))    # [:,:,None] usefull only in 2+D  Ids.repeat(1,1,d) with d \\in [1,3]\n        self.nodes_values   = self.nodes_values.to(shape_functions.dtype)\n        u = torch.einsum('gi...,gi-&gt;g',self.nodes_values,shape_functions)   \n\n        if self.training : \n\n            return u, x_g, detJ\n        else:\n            return u\n\n\n\n\nCode\nmodel = interpolation1D(nodes, elements)\nmodel.train()\nprint(\"* Model set in training mode\")\n\n\n* Model set in training mode",
    "crumbs": [
      "{{< iconify fa6-solid:rocket width=17 title=HAL >}}",
      "1D NeuROM",
      "Adam"
    ]
  },
  {
    "objectID": "demos/1D_element_based.html#training-with-batch-version",
    "href": "demos/1D_element_based.html#training-with-batch-version",
    "title": "Element based 1D HideNN-FEM - ADAM training",
    "section": "Training with batch version",
    "text": "Training with batch version\n\nSupervised learning\nLet’s first try to learn a cosine function using supervised learning\n\n\nCode\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.1)\nMSE = nn.MSELoss()\n# Training\nNepoch          = 100\nlossList        = []\nlossTraining    = []\nmodel.train()\nfor i in range(Nepoch):\n    u, x_g, detJ    = model()\n    loss            = MSE(u,torch.sin(x_g)[:,0])\n    optimizer.zero_grad()    \n    loss.backward()          \n    optimizer.step()\n    lossTraining.append(loss.data)\n    print(f\"{i = } | loss = {loss.data :.2e}\", end = \"\\r\")\n\n\ni = 99 | loss = 1.02e-05\n\n\n\nPost-processing\n\n\nCode\nimport matplotlib.pyplot as plt\n\n# plt.figure()\n# plt.semilogy(lossTraining)\n# plt.xlabel(\"Epochs\")\n# plt.ylabel(\"Loss\")\n# plt.show()\n\nfig = go.Figure()\n\n\nfig.add_trace(go.Scatter( y=lossTraining, mode='lines+markers', name='du/dx', line=dict(color='#01426a')\n))\n\nfig.update_layout(\n    margin=dict(l=0, r=0, t=0, b=0),\n    plot_bgcolor='rgba(0,0,0,0)',  # Remove background color\n    width=700, \n    height=400,  \n    xaxis=dict(title='Epochs',\n    showgrid=True,\n    gridcolor='lightgray'),\n    yaxis=dict(title='Loss',\n    showgrid=True,\n    gridcolor='lightgray',\n    titlefont=dict(color='#01426a'),\n    tickfont=dict(color='#01426a'),),\n)\n\nfig.show()\n\n\n                                                \n\n\n\n\nCode\nmodel.eval()\n\nx_test = torch.linspace(0,6,30)\nu_eval = model(x_test)\n# plt.figure()\n# plt.plot(x_g.data,u.data, '+',label='Gauss points')\n# plt.plot(x_test.data,u_eval.data, 'o',label='Test points')\n# plt.xlabel(\"x [mm]\")\n# plt.ylabel(\"u(x) [mm]\")\n# plt.legend()  \n# plt.show()\n\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=x_g.data[:,0], y=u.data, mode='markers', marker=dict(symbol='cross'), name='Gauss points',    line=dict(color='#01426a')))\n\nfig.add_trace(go.Scatter(x=x_test.data, y=u_eval.data, mode='markers', marker=dict(symbol='circle'), name='Test points', line=dict(color='#CE0037')))\n\nfig.update_layout(\n    margin=dict(l=0, r=0, t=0, b=0),\n    plot_bgcolor='rgba(0,0,0,0)',  # Remove background color\n    width=700, \n    height=400,  \n    xaxis=dict(title='x [mm]',\n    showgrid=True,\n    gridcolor='lightgray'),\n    yaxis=dict(title='u(x) [mm]',\n    showgrid=True,\n    gridcolor='lightgray',\n    titlefont=dict(color='#01426a'),\n    tickfont=dict(color='#01426a'),),    \n    legend=dict(x=0, y=1, traceorder=\"normal\")\n)\n\nfig.show()\n\n\n                                                \n\n\n\n\nCode\nmodel.train()\nu, x_g, detJ    = model()\ndu_dxg = torch.autograd.grad(u, x_g, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n# plt.figure()\n# plt.plot(x_g.data,du_dxg.data, '-o')\n# plt.xlabel(\"x [mm]\")\n# plt.ylabel(\"du/dx [mm/mm]\")\n# plt.show()\n\nfig = go.Figure()\n\nx_data = x_g.data.numpy()[:,0]\ny_data = du_dxg.data.numpy()[:,0]\nfig.add_trace(go.Scatter(x=x_data, y=y_data, mode='lines+markers', name='du/dx', line=dict(color='#01426a')\n))\n\nfig.update_layout(\n    margin=dict(l=0, r=0, t=0, b=0),\n    plot_bgcolor='rgba(0,0,0,0)',  # Remove background color\n    width=700, \n    height=400,  \n    xaxis=dict(title='x [mm]',\n    showgrid=True,\n    gridcolor='lightgray'),\n    yaxis=dict(title='du/dx [mm/mm]',\n    showgrid=True,\n    gridcolor='lightgray',\n    titlefont=dict(color='#01426a'),\n    tickfont=dict(color='#01426a'),),\n)\n\nfig.show()\n\n\n                                                \n\n\n\n\n\nUnsupervised learning\nLet’s now try to solve a partial derivative equation (PDE) defined at the begining of this notebook.\n\nPure Adam training\n\n\nCode\ndef PotentialEnergy(u,x,f,J):\n    \"\"\"Computes the potential energy of the Beam, which will be used as the loss of the HiDeNN\"\"\"\n    du_dx = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n    # Vectorised calculation of the integral terms\n    int_term1 =  0.5 * du_dx*du_dx * J\n    int_term2 =  f(x) * J * u\n\n    # Vectorised calculation of the integral using the trapezoidal rule\n    integral = torch.sum(int_term1 - int_term2)\n    return integral\n\ndef f(x):\n    return 1000 #-x*(x-10)\n\n\n\n\nCode\noptimizer = torch.optim.Adam(model.parameters(), lr = 1)\n# Training\nNepoch          = 7000\nlossList        = []\nlossTraining    = []\nmodel.train()\nfor i in range(Nepoch):\n    u, x_g, detJ    = model()\n    loss            = PotentialEnergy(u,x_g,f,detJ)\n    optimizer.zero_grad()    \n    loss.backward()          \n    optimizer.step()\n    lossTraining.append(loss.data)\n    print(f\"{i = } | loss = {loss.data :.2e}\", end = \"\\r\")\n\n\ni = 147 | loss = -3.16e+07i = 6999 | loss = -4.02e+08\n\n\n\nPost-processing\nHere the loss can be negative so a log plot is not (directly) possible\n\n\nCode\nimport matplotlib.pyplot as plt\n\n# plt.figure()\n# plt.plot(lossTraining)\n# plt.xlabel(\"Epochs\")\n# plt.ylabel(\"Loss\")\n# plt.show()\n\nfig = go.Figure()\n\n\nfig.add_trace(go.Scatter( y=lossTraining, mode='lines+markers', name='du/dx', line=dict(color='#01426a')\n))\n\nfig.update_layout(\n    margin=dict(l=0, r=0, t=0, b=0),\n    plot_bgcolor='rgba(0,0,0,0)',  # Remove background color\n    width=700, \n    height=400,  \n    xaxis=dict(title='Epochs',\n    showgrid=True,\n    gridcolor='lightgray'),\n    yaxis=dict(title='Loss',\n    showgrid=True,\n    gridcolor='lightgray',\n    titlefont=dict(color='#01426a'),\n    tickfont=dict(color='#01426a'),),\n)\n\nfig.show()\n\n\n                                                \n\n\n\n\nCode\nmodel.eval()\n\nx_test = torch.linspace(0,6,30)\nu_eval = model(x_test)\n# plt.figure()\n# plt.plot(x_g.data,u.data, '+',label='Gauss points')\n# plt.plot(x_test.data,u_eval.data, 'o',label='Test points')\n# plt.xlabel(\"x [mm]\")\n# plt.ylabel(\"u(x) [mm]\")\n# plt.legend()\n# plt.show() \n\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=x_g.data[:,0], y=u.data, mode='markers', marker=dict(symbol='cross'), name='Gauss points',    line=dict(color='#01426a')))\n\nfig.add_trace(go.Scatter(x=x_test.data, y=u_eval.data, mode='markers', marker=dict(symbol='circle'), name='Test points', line=dict(color='#CE0037')))\n\nfig.update_layout(\n    margin=dict(l=0, r=0, t=0, b=0),\n    plot_bgcolor='rgba(0,0,0,0)',  # Remove background color\n    width=700, \n    height=400,  \n    xaxis=dict(title='x [mm]',\n    showgrid=True,\n    gridcolor='lightgray'),\n    yaxis=dict(title='u(x) [mm]',\n    showgrid=True,\n    gridcolor='lightgray',\n    titlefont=dict(color='#01426a'),\n    tickfont=dict(color='#01426a'),),    \n    legend=dict(x=0, y=1, traceorder=\"normal\")\n)\n\nfig.show()\n\n\n                                                \n\n\n\n\nCode\nmodel.train()\nu, x_g, detJ    = model()\ndu_dxg = torch.autograd.grad(u, x_g, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n# plt.figure()\n# plt.plot(x_g.data,du_dxg.data, '-o')\n# plt.xlabel(\"x [mm]\")\n# plt.ylabel(\"du/dx [mm/mm]\")\n# plt.show()\n\nfig = go.Figure()\n\nx_data = x_g.data.numpy()[:,0]\ny_data = du_dxg.data.numpy()[:,0]\nfig.add_trace(go.Scatter(x=x_data, y=y_data, mode='lines+markers', name='du/dx', line=dict(color='#01426a')\n))\n\nfig.update_layout(\n    margin=dict(l=0, r=0, t=0, b=0),\n    plot_bgcolor='rgba(0,0,0,0)',  # Remove background color\n    width=700, \n    height=400,  \n    xaxis=dict(title='x [mm]',\n    showgrid=True,\n    gridcolor='lightgray'),\n    yaxis=dict(title='du/dx [mm/mm]',\n    showgrid=True,\n    gridcolor='lightgray',\n    titlefont=dict(color='#01426a'),\n    tickfont=dict(color='#01426a'),),\n)\n\nfig.show()\n\n\n                                                \n\n\n\n\n\nPure L-BFGS training\n\n\nCode\nmodel = interpolation1D(nodes, elements)\nprint(\"* Reset model\")\n\nmodel.train()\n\noptimizer = torch.optim.LBFGS(model.parameters(),\n                line_search_fn=\"strong_wolfe\")\n# Training\nNepoch          = 10\nlossList        = []\nlossTraining    = []\n\ndef closure():\n    optimizer.zero_grad()\n    u, x_g, detJ    = model()\n    loss            = PotentialEnergy(u,x_g,f,detJ)\n    loss.backward()\n    return loss\n\nmodel.train()\nfor i in range(Nepoch):\n    optimizer.step(closure)\n    loss = closure()\n    lossTraining.append(loss.data)\n    print(f\"{i = } | loss = {loss.data :.2e}\", end = \"\\r\")\n\n\n* Reset model\ni = 9 | loss = -4.02e+08\n\n\n\nPost-processing\n\n\nCode\nimport matplotlib.pyplot as plt\n\n# plt.figure()\n# plt.plot(lossTraining)\n# plt.xlabel(\"Epochs\")\n# plt.ylabel(\"Loss\")\n# plt.show()\n\nfig = go.Figure()\n\n\nfig.add_trace(go.Scatter( y=lossTraining, mode='lines+markers', name='du/dx', line=dict(color='#01426a')\n))\n\nfig.update_layout(\n    margin=dict(l=0, r=0, t=0, b=0),\n    plot_bgcolor='rgba(0,0,0,0)',  # Remove background color\n    width=700, \n    height=400,  \n    xaxis=dict(title='Epochs',\n    showgrid=True,\n    gridcolor='lightgray'),\n    yaxis=dict(title='Loss',\n    tickvals=[-4.022e8, -4.016e8, -4.008e8],\n    ticktext=['-4.022e8', '-4.016e8', '-4.008e8'],\n    showgrid=True,\n    gridcolor='lightgray',\n    titlefont=dict(color='#01426a'),\n    tickfont=dict(color='#01426a'),),\n)\n\nfig.show()\n\n\n                                                \n\n\n\n\nCode\nmodel.train()\n\nu, x_g, detJ    = model()\n\nmodel.eval()\n\nx_test = torch.linspace(0,6,30)\nu_eval = model(x_test)\n# plt.figure()\n# plt.plot(x_g.data,u.data, '+',label='Gauss points')\n# plt.plot(x_test.data,u_eval.data, 'o',label='Test points')\n# plt.xlabel(\"x [mm]\")\n# plt.ylabel(\"u(x) [mm]\")\n# plt.legend()\n# plt.show() \n\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=x_g.data[:,0], y=u.data, mode='markers', marker=dict(symbol='cross'), name='Gauss points',    line=dict(color='#01426a')))\n\nfig.add_trace(go.Scatter(x=x_test.data, y=u_eval.data, mode='markers', marker=dict(symbol='circle'), name='Test points', line=dict(color='#CE0037')))\n\nfig.update_layout(\n    margin=dict(l=0, r=0, t=0, b=0),\n    plot_bgcolor='rgba(0,0,0,0)',  # Remove background color\n    width=700, \n    height=400,  \n    xaxis=dict(title='x [mm]',\n    showgrid=True,\n    gridcolor='lightgray'),\n    yaxis=dict(title='u(x) [mm]',\n    showgrid=True,\n    gridcolor='lightgray',\n    titlefont=dict(color='#01426a'),\n    tickfont=dict(color='#01426a'),),    \n    legend=dict(x=0, y=1, traceorder=\"normal\")\n)\n\nfig.show()\n\n\n                                                \n\n\n\n\nCode\nmodel.train()\nu, x_g, detJ    = model()\ndu_dxg = torch.autograd.grad(u, x_g, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n# plt.figure()\n# plt.plot(x_g.data,du_dxg.data, '-o')\n# plt.xlabel(\"x [mm]\")\n# plt.ylabel(\"du/dx [mm/mm]\")\n# plt.show()\n\nfig = go.Figure()\n\nx_data = x_g.data.numpy()[:,0]\ny_data = du_dxg.data.numpy()[:,0]\nfig.add_trace(go.Scatter(x=x_data, y=y_data, mode='lines+markers', name='du/dx', line=dict(color='#01426a')\n))\n\nfig.update_layout(\n    margin=dict(l=0, r=0, t=0, b=0),\n    plot_bgcolor='rgba(0,0,0,0)',  # Remove background color\n    width=700, \n    height=400,  \n    xaxis=dict(title='x [mm]',\n    showgrid=True,\n    gridcolor='lightgray'),\n    yaxis=dict(title='du/dx [mm/mm]',\n    showgrid=True,\n    gridcolor='lightgray',\n    titlefont=dict(color='#01426a'),\n    tickfont=dict(color='#01426a'),),\n)\n\nfig.show()",
    "crumbs": [
      "{{< iconify fa6-solid:rocket width=17 title=HAL >}}",
      "1D NeuROM",
      "Adam"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A simplified 1D NeuROM demo !",
    "section": "",
    "text": "Welcome!\n\nThese demos are based on the NeuROM-py code .\nThe notebooks can be executed online with binder  (no download required).",
    "crumbs": [
      "{{< iconify fa6-solid:rocket width=17 title=HAL >}}",
      "Home"
    ]
  },
  {
    "objectID": "demos/1D_element_based_LBFGS.html",
    "href": "demos/1D_element_based_LBFGS.html",
    "title": "Element based 1D HideNN-FEM - L-BFGS training",
    "section": "",
    "text": "\\(\\forall v\\in V(\\Omega),\\) find \\(u\\in H(\\Omega)\\),\n\\[\\int_\\Omega \\nabla v \\cdot \\lambda(x) \\nabla u = \\int_\\Omega f v  + \\int_{\\partial \\Omega_N} g v\\]\n\n\nCode\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport plotly.io as pio\npio.renderers.default = \"notebook\"\n\ntorch.set_default_dtype(torch.float32)\n\n\n\n\nWe recode 1D shape functions in HideNN-FEM (first order).\n\n\nCode\nclass mySF1D_elementBased(nn.Module):    \n    def __init__(self, left = -1.,  right = 1.):\n        super().__init__()        \n        \n        self.left   = left\n        self.right  = right\n\n        # To easily transfer to CUDA or change dtype of whole model\n        self.register_buffer('one', torch.tensor([1], dtype=torch.float32))\n\n    def forward(self, x=None, training=False):  \n        if training : x = (self.left + self.right) / torch.tensor(2., requires_grad=True) \n        sf1 = - (x - self.left) / (self.right - self.left) + self.one\n        sf2 = (x - self.left)/(self.right - self.left)\n        if training : return  sf1, sf2, self.right - self.left, x\n        else : return  sf1, sf2\n\n\nl, r    =  -0.9, 0.3\nmySF    = mySF1D_elementBased(left = l, right = r)\n\nXX      = torch.linspace(l,r,100)\ns1, s2  = mySF(XX)\n# plt.plot(XX.data, s1.data,label='N1')\n# plt.plot(XX.data, s2.data,label='N2')\n# plt.grid()\n# plt.xlabel(\"x [mm]\")\n# plt.ylabel(\"shape functions\")\n# plt.legend()  \n# plt.show()\n\n\n\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=XX.data, y=s1.data, name='N1',    line=dict(color='#01426a')))\n\nfig.add_trace(go.Scatter(x=XX.data, y=s2.data, name='N2', line=dict(color='#CE0037')))\n\nfig.update_layout(\n    margin=dict(l=0, r=0, t=0, b=0),\n    plot_bgcolor='rgba(0,0,0,0)',  # Remove background color\n    width=700, \n    height=400,  \n    xaxis=dict(title='x [mm]',\n    showgrid=True,\n    gridcolor='lightgray'),\n    yaxis=dict(title='u(x) [mm]',\n    showgrid=True,\n    gridcolor='lightgray',\n    titlefont=dict(color='#01426a'),\n    tickfont=dict(color='#01426a'),),    \n    legend=dict(x=0, y=1, traceorder=\"normal\")\n)\n\nfig.show()\n\n\n\n\n                                                \n\n\n\n\n\nWe recode 1D shape functions in HideNN-FEM (first order).\nA vectorised implementation enables batch processing of several points evaluation which in terns enables batch wise differentiation.\n\nIn non-batched implementation\n\ndu_dx = [torch.autograd.grad(u[i], x[i], grad_outputs=torch.ones_like(u[i]), create_graph=True) for i,_ in enumerate(u)\n\nWith the batched version\n\ndu_dx = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)\n\n\n\n\nCode\nclass mySF1D_elementBased_vectorised(nn.Module):\n    def __init__(self, connectivity):\n        super(mySF1D_elementBased_vectorised, self).__init__()\n        if connectivity.dim == 1:\n            connectivity = connectivity[:,None]\n        self.connectivity = connectivity\n        self.register_buffer('GaussPoint',self.GP())\n        self.register_buffer('w_g',torch.tensor(1.0))\n\n\n    def UpdateConnectivity(self,connectivity):\n        self.connectivity = connectivity.astype(int)\n\n    def GP(self):\n        \"Defines the position of the intergration point(s) for the given element\"\n\n        return torch.tensor([[1/2, 1/2]], requires_grad=True)                                       # a1, a2, th 2 area coordinates\n\n    def forward(self, \n                x               : torch.Tensor  = None  , \n                cell_id         : list          = None  , \n                coordinates     : torch.Tensor  = None  , \n                flag_training   : bool          = False):\n\n        assert coordinates is not None, \"No nodes coordinates provided. Aborting\"\n\n        cell_nodes_IDs  = self.connectivity[cell_id,:].T\n        Ids             = torch.as_tensor(cell_nodes_IDs).to(coordinates.device).t()[:,:,None]      # :,:,None] usefull only in 2+D  \n        nodes_coord     = torch.gather(coordinates[:,None,:].repeat(1,2,1),0, Ids.repeat(1,1,1))    # [:,:,None] usefull only in 2+D  Ids.repeat(1,1,d) with d \\in [1,3]\n        \n        nodes_coord = nodes_coord.to(self.GaussPoint.dtype)\n\n        if flag_training:\n            refCoordg   = self.GaussPoint.repeat(cell_id.shape[0],1)\n            Ng          = refCoordg\n            x_g         = torch.einsum('enx,en-&gt;ex',nodes_coord,Ng)\n            refCoord    = self.GetRefCoord(x_g,nodes_coord)\n            N           = refCoord\n            detJ        = nodes_coord[:,1] - nodes_coord[:,0]\n            return N, x_g, detJ*self.w_g\n\n        else:\n            refCoord = self.GetRefCoord(x,nodes_coord)\n            N = torch.stack((refCoord[:,0], refCoord[:,1]),dim=1) \n            return N\n\n    \n    def GetRefCoord(self,x, nodes_coord):\n        InverseMapping          = torch.ones([int(nodes_coord.shape[0]), 2, 2], dtype=x.dtype, device=x.device)\n        detJ                    = nodes_coord[:,0,0] - nodes_coord[:,1,0]\n        InverseMapping[:,0,1]   = -nodes_coord[:,1,0]\n        InverseMapping[:,1,1]   = nodes_coord[:,0,0]\n        InverseMapping[:,1,0]   = -1*InverseMapping[:,1,0]\n        InverseMapping[:,:,:]  /= detJ[:,None,None]\n        x_extended = torch.stack((x, torch.ones_like(x)),dim=1)\n\n\n        return torch.einsum('eij,ej...-&gt;ei',InverseMapping,x_extended.squeeze(1))\n\n\n\n\nIn 1D, for P1 elements, there are two shape functions per element, \\(N_1\\left(\\xi\\right)\\) and \\(N_2\\left(\\xi\\right)\\), \\(\\xi \\in \\left[0,1\\right]\\) being the coordinate in the reference element space.\nThe iso-parametric idea relies on using the same interpolation for the space coordinates as is used for the QoIs, which means that space is interpolated using the same shape functions as the displacement is for instance. Thus, the real space coordinate \\(x\\) satisfies * \\(x = \\sum_{i=1}^{2}N_i\\left(\\xi \\right) x_i\\),\nwith \\(x_i\\) the coordinate of the node associated with the \\(i-\\)th shape function.\nSuch mapping can be expressed using the area coordinates \\(a_1\\) and \\(a_2\\) (such that \\(N_1\\left(\\xi\\right) = a_1\\) and \\(N_2\\left(\\xi\\right) = a_2\\)).\n\\(\\begin{pmatrix}\nx \\\\\n1\n\\end{pmatrix} = \\underbrace{\\begin{bmatrix}\nx_1 & x_2\\\\\n1 & 1\n\\end{bmatrix}}_{\\mathcal{M}} \\begin{pmatrix}\na_1 \\\\\na_2\n\\end{pmatrix}.\\)\nReciprocally (for non degenerated elements),\n\\(\\begin{pmatrix}\na_1 \\\\\na_2\n\\end{pmatrix} = \\underbrace{\\frac{1}{x_1 - x_2}\\begin{bmatrix}\n1 & -x_2\\\\\n-1 & x_1\n\\end{bmatrix}}_{\\mathcal{M}^{-1}} \\begin{pmatrix}\nx \\\\\n1\n\\end{pmatrix}.\\)\n\n\n\n\n\n\nCode\nN           = 40\nnodes       = torch.linspace(0,6.28,N)\nnodes       = nodes[:,None]\nelements    = torch.vstack([torch.arange(0,N-1),torch.arange(1,N)]).T\n\n\n\n\n\n\n\nCode\nclass interpolation1D(nn.Module):    \n    def __init__(self, \n            nodes           : torch.Tensor  = None  , \n            elements        : list          = None  , \n            dirichlet       : list          =[0,nodes.shape[0]-1]     ,                 # Fixed nodes (by default, 2 extremities of the beam)\n            n_components    : int           = 1     ):                                  # Number of dofs per node \n        super().__init__()        \n        self.register_buffer('nodes', nodes)\n        self.coordinates =nn.ParameterDict({\n                                    'all': self.nodes,\n                                    })                                                  # Should use different entries for trainable and fixed coordinates\n\n        \n        self.coordinates[\"all\"].requires_grad   = False \n        self.n_components                       = n_components\n        self.register_buffer('values',0.5*torch.ones((self.coordinates[\"all\"].shape[0], self.n_components)))\n        self.dirichlet = dirichlet\n\n        \n        self.elements = elements\n\n        self.Ne = len(elements)\n\n        self.shape_functions = mySF1D_elementBased_vectorised(elements)                 \n\n        # To easily transfer to CUDA or change dtype of whole model\n        self.register_buffer('one', torch.tensor([1], dtype=torch.float32))\n\n        self.SetBCs()\n\n    def SetBCs(self):\n        assert self.n_components == 1, \"only scalar field implemented. Aborting\"\n        if self.n_components == 1:\n            self.dofs_free                  = (torch.ones_like(self.values[:])==1)[:,0]\n            self.dofs_free[self.dirichlet]  = False\n            \n\n\n            nodal_values_imposed            = 0*self.values[~self.dofs_free,:]              # Not generic yet, only 0 BCs\n\n\n            nodal_values_free               = self.values[self.dofs_free,:] \n            self.nodal_values               = nn.ParameterDict({\n                                                'free'      : nodal_values_free,\n                                                'imposed'   : nodal_values_imposed,\n                                                })\n            self.nodal_values['imposed'].requires_grad = False\n\n    def forward(self, x = None): \n        if self.training :\n            k_elt = torch.arange(0,self.Ne)\n        else :\n            k_elt = []\n            for xx in x:\n                for k in range(self.Ne):\n                    elt = self.elements[k]\n                    if xx &gt;= self.coordinates[\"all\"][elt[0]] and xx &lt;= self.coordinates[\"all\"][elt[1]]:\n                        k_elt.append(k)\n                        break\n        if self.training : \n            shape_functions, x_g, detJ = self.shape_functions(\n                x               = x                 , \n                cell_id         = k_elt             , \n                coordinates     = self.nodes        , \n                flag_training   = self.training     )\n        else:\n            shape_functions = self.shape_functions(\n                x               = x                 , \n                cell_id         = k_elt             , \n                coordinates     = self.nodes        , \n                flag_training   = self.training     )\n        # Batch interpolation of the solution using the computed shape functions batch\n        nodal_values_tensor                     = torch.ones_like(self.values)\n        nodal_values_tensor[self.dofs_free,:]   = self.nodal_values['free']\n        nodal_values_tensor[~self.dofs_free,:]  = self.nodal_values['imposed']                    \n\n        cell_nodes_IDs      = self.elements[k_elt,:].T\n        Ids                 = torch.as_tensor(cell_nodes_IDs).to(nodal_values_tensor.device).t()[:,:,None]      # :,:,None] usefull only in 2+D  \n\n        \n        self.nodes_values   = torch.gather(nodal_values_tensor[:,None,:].repeat(1,2,1),0, Ids.repeat(1,1,1))    # [:,:,None] usefull only in 2+D  Ids.repeat(1,1,d) with d \\in [1,3]\n        self.nodes_values   = self.nodes_values.to(shape_functions.dtype)\n        u = torch.einsum('gi...,gi-&gt;g',self.nodes_values,shape_functions)   \n\n        if self.training : \n\n            return u, x_g, detJ\n        else:\n            return u\n\n\n\n\nCode\nmodel = interpolation1D(nodes, elements)\nmodel.train()\nprint(\"* Model set in training mode\")\n\n\n* Model set in training mode\n\n\n\n\n\n\n\nCode\ndef PotentialEnergy(u,x,f,J):\n    \"\"\"Computes the potential energy of the Beam, which will be used as the loss of the HiDeNN\"\"\"\n    du_dx = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n    # Vectorised calculation of the integral terms\n    int_term1 =  0.5 * du_dx*du_dx * J\n    int_term2 =  f(x) * J * u\n\n    # Vectorised calculation of the integral using the trapezoidal rule\n    integral = torch.sum(int_term1 - int_term2)\n    return integral\n\ndef f(x):\n    return 1000 #-x*(x-10)\n\n\n\n\nCode\n\noptimizer = torch.optim.LBFGS(model.parameters(),\n                line_search_fn=\"strong_wolfe\")\n# Training\nNepoch          = 10\nlossList        = []\nlossTraining    = []\n\ndef closure():\n    optimizer.zero_grad()\n    u, x_g, detJ    = model()\n    loss            = PotentialEnergy(u,x_g,f,detJ)\n    loss.backward()\n    return loss\n\nmodel.train()\nfor i in range(Nepoch):\n    optimizer.step(closure)\n    loss = closure()\n    lossTraining.append(loss.data)\n    print(f\"{i = } | loss = {loss.data :.2e}\", end = \"\\r\")\n\n\ni = 9 | loss = -4.02e+08\n\n\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\n\n# plt.figure()\n# plt.plot(lossTraining)\n# plt.xlabel(\"Epochs\")\n# plt.ylabel(\"Loss\")\n# plt.show()\n\n\n\nfig = go.Figure()\n\n\nfig.add_trace(go.Scatter( y=lossTraining, mode='lines+markers', name='du/dx', line=dict(color='#01426a')\n))\n\nfig.update_layout(\n    margin=dict(l=0, r=0, t=0, b=0),\n    plot_bgcolor='rgba(0,0,0,0)',  # Remove background color\n    width=700, \n    height=400,  \n    xaxis=dict(title='Epochs',\n    showgrid=True,\n    gridcolor='lightgray'),\n    yaxis=dict(title='Loss',\n    tickvals=[-4.022e8, -4.016e8, -4.008e8],\n    ticktext=['-4.022e8', '-4.016e8', '-4.008e8'],\n    showgrid=True,\n    gridcolor='lightgray',\n    titlefont=dict(color='#01426a'),\n    tickfont=dict(color='#01426a'),),\n)\n\nfig.show()\n\n\n                                                \n\n\n\n\nCode\nmodel.train()\n\nu, x_g, detJ    = model()\n\nmodel.eval()\n\nx_test = torch.linspace(0,6,30)\nu_eval = model(x_test)\n# plt.figure()\n# plt.plot(x_g.data,u.data, '+',label='Gauss points')\n# plt.plot(x_test.data,u_eval.data, 'o',label='Test points')\n# plt.xlabel(\"x [mm]\")\n# plt.ylabel(\"u(x) [mm]\")\n# plt.legend()\n# plt.show() \n\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=x_g.data[:,0], y=u.data, mode='markers', marker=dict(symbol='cross'), name='Gauss points',    line=dict(color='#01426a')))\n\nfig.add_trace(go.Scatter(x=x_test.data, y=u_eval.data, mode='markers', marker=dict(symbol='circle'), name='Test points', line=dict(color='#CE0037')))\n\nfig.update_layout(\n    margin=dict(l=0, r=0, t=0, b=0),\n    plot_bgcolor='rgba(0,0,0,0)',  # Remove background color\n    width=700, \n    height=400,  \n    xaxis=dict(title='x [mm]',\n    showgrid=True,\n    gridcolor='lightgray'),\n    yaxis=dict(title='u(x) [mm]',\n    showgrid=True,\n    gridcolor='lightgray',\n    titlefont=dict(color='#01426a'),\n    tickfont=dict(color='#01426a'),),    \n    legend=dict(x=0, y=1, traceorder=\"normal\")\n)\n\nfig.show()\n\n\n                                                \n\n\n\n\nCode\nmodel.train()\nu, x_g, detJ    = model()\ndu_dxg = torch.autograd.grad(u, x_g, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n# plt.figure()\n# plt.plot(x_g.data,du_dxg.data, '-o')\n# plt.xlabel(\"x [mm]\")\n# plt.ylabel(\"du/dx [mm/mm]\")\n# plt.show()\n\nfig = go.Figure()\n\nx_data = x_g.data.numpy()[:,0]\ny_data = du_dxg.data.numpy()[:,0]\nfig.add_trace(go.Scatter(x=x_data, y=y_data, mode='lines+markers', name='du/dx', line=dict(color='#01426a')\n))\n\nfig.update_layout(\n    margin=dict(l=0, r=0, t=0, b=0),\n    plot_bgcolor='rgba(0,0,0,0)',  # Remove background color\n    width=700, \n    height=400,  \n    xaxis=dict(title='x [mm]',\n    showgrid=True,\n    gridcolor='lightgray'),\n    yaxis=dict(title='du/dx [mm/mm]',\n    showgrid=True,\n    gridcolor='lightgray',\n    titlefont=dict(color='#01426a'),\n    tickfont=dict(color='#01426a'),),\n)\n\n\nfig.show()",
    "crumbs": [
      "{{< iconify fa6-solid:rocket width=17 title=HAL >}}",
      "1D NeuROM",
      "L-BFGS"
    ]
  },
  {
    "objectID": "demos/1D_element_based_LBFGS.html#space-interpolation-legacy",
    "href": "demos/1D_element_based_LBFGS.html#space-interpolation-legacy",
    "title": "Element based 1D HideNN-FEM - L-BFGS training",
    "section": "",
    "text": "We recode 1D shape functions in HideNN-FEM (first order).\n\n\nCode\nclass mySF1D_elementBased(nn.Module):    \n    def __init__(self, left = -1.,  right = 1.):\n        super().__init__()        \n        \n        self.left   = left\n        self.right  = right\n\n        # To easily transfer to CUDA or change dtype of whole model\n        self.register_buffer('one', torch.tensor([1], dtype=torch.float32))\n\n    def forward(self, x=None, training=False):  \n        if training : x = (self.left + self.right) / torch.tensor(2., requires_grad=True) \n        sf1 = - (x - self.left) / (self.right - self.left) + self.one\n        sf2 = (x - self.left)/(self.right - self.left)\n        if training : return  sf1, sf2, self.right - self.left, x\n        else : return  sf1, sf2\n\n\nl, r    =  -0.9, 0.3\nmySF    = mySF1D_elementBased(left = l, right = r)\n\nXX      = torch.linspace(l,r,100)\ns1, s2  = mySF(XX)\n# plt.plot(XX.data, s1.data,label='N1')\n# plt.plot(XX.data, s2.data,label='N2')\n# plt.grid()\n# plt.xlabel(\"x [mm]\")\n# plt.ylabel(\"shape functions\")\n# plt.legend()  \n# plt.show()\n\n\n\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=XX.data, y=s1.data, name='N1',    line=dict(color='#01426a')))\n\nfig.add_trace(go.Scatter(x=XX.data, y=s2.data, name='N2', line=dict(color='#CE0037')))\n\nfig.update_layout(\n    margin=dict(l=0, r=0, t=0, b=0),\n    plot_bgcolor='rgba(0,0,0,0)',  # Remove background color\n    width=700, \n    height=400,  \n    xaxis=dict(title='x [mm]',\n    showgrid=True,\n    gridcolor='lightgray'),\n    yaxis=dict(title='u(x) [mm]',\n    showgrid=True,\n    gridcolor='lightgray',\n    titlefont=dict(color='#01426a'),\n    tickfont=dict(color='#01426a'),),    \n    legend=dict(x=0, y=1, traceorder=\"normal\")\n)\n\nfig.show()",
    "crumbs": [
      "{{< iconify fa6-solid:rocket width=17 title=HAL >}}",
      "1D NeuROM",
      "L-BFGS"
    ]
  },
  {
    "objectID": "demos/1D_element_based_LBFGS.html#vectorised-version-of-the-element-based-implementation",
    "href": "demos/1D_element_based_LBFGS.html#vectorised-version-of-the-element-based-implementation",
    "title": "Element based 1D HideNN-FEM - L-BFGS training",
    "section": "",
    "text": "We recode 1D shape functions in HideNN-FEM (first order).\nA vectorised implementation enables batch processing of several points evaluation which in terns enables batch wise differentiation.\n\nIn non-batched implementation\n\ndu_dx = [torch.autograd.grad(u[i], x[i], grad_outputs=torch.ones_like(u[i]), create_graph=True) for i,_ in enumerate(u)\n\nWith the batched version\n\ndu_dx = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)\n\n\n\n\nCode\nclass mySF1D_elementBased_vectorised(nn.Module):\n    def __init__(self, connectivity):\n        super(mySF1D_elementBased_vectorised, self).__init__()\n        if connectivity.dim == 1:\n            connectivity = connectivity[:,None]\n        self.connectivity = connectivity\n        self.register_buffer('GaussPoint',self.GP())\n        self.register_buffer('w_g',torch.tensor(1.0))\n\n\n    def UpdateConnectivity(self,connectivity):\n        self.connectivity = connectivity.astype(int)\n\n    def GP(self):\n        \"Defines the position of the intergration point(s) for the given element\"\n\n        return torch.tensor([[1/2, 1/2]], requires_grad=True)                                       # a1, a2, th 2 area coordinates\n\n    def forward(self, \n                x               : torch.Tensor  = None  , \n                cell_id         : list          = None  , \n                coordinates     : torch.Tensor  = None  , \n                flag_training   : bool          = False):\n\n        assert coordinates is not None, \"No nodes coordinates provided. Aborting\"\n\n        cell_nodes_IDs  = self.connectivity[cell_id,:].T\n        Ids             = torch.as_tensor(cell_nodes_IDs).to(coordinates.device).t()[:,:,None]      # :,:,None] usefull only in 2+D  \n        nodes_coord     = torch.gather(coordinates[:,None,:].repeat(1,2,1),0, Ids.repeat(1,1,1))    # [:,:,None] usefull only in 2+D  Ids.repeat(1,1,d) with d \\in [1,3]\n        \n        nodes_coord = nodes_coord.to(self.GaussPoint.dtype)\n\n        if flag_training:\n            refCoordg   = self.GaussPoint.repeat(cell_id.shape[0],1)\n            Ng          = refCoordg\n            x_g         = torch.einsum('enx,en-&gt;ex',nodes_coord,Ng)\n            refCoord    = self.GetRefCoord(x_g,nodes_coord)\n            N           = refCoord\n            detJ        = nodes_coord[:,1] - nodes_coord[:,0]\n            return N, x_g, detJ*self.w_g\n\n        else:\n            refCoord = self.GetRefCoord(x,nodes_coord)\n            N = torch.stack((refCoord[:,0], refCoord[:,1]),dim=1) \n            return N\n\n    \n    def GetRefCoord(self,x, nodes_coord):\n        InverseMapping          = torch.ones([int(nodes_coord.shape[0]), 2, 2], dtype=x.dtype, device=x.device)\n        detJ                    = nodes_coord[:,0,0] - nodes_coord[:,1,0]\n        InverseMapping[:,0,1]   = -nodes_coord[:,1,0]\n        InverseMapping[:,1,1]   = nodes_coord[:,0,0]\n        InverseMapping[:,1,0]   = -1*InverseMapping[:,1,0]\n        InverseMapping[:,:,:]  /= detJ[:,None,None]\n        x_extended = torch.stack((x, torch.ones_like(x)),dim=1)\n\n\n        return torch.einsum('eij,ej...-&gt;ei',InverseMapping,x_extended.squeeze(1))\n\n\n\n\nIn 1D, for P1 elements, there are two shape functions per element, \\(N_1\\left(\\xi\\right)\\) and \\(N_2\\left(\\xi\\right)\\), \\(\\xi \\in \\left[0,1\\right]\\) being the coordinate in the reference element space.\nThe iso-parametric idea relies on using the same interpolation for the space coordinates as is used for the QoIs, which means that space is interpolated using the same shape functions as the displacement is for instance. Thus, the real space coordinate \\(x\\) satisfies * \\(x = \\sum_{i=1}^{2}N_i\\left(\\xi \\right) x_i\\),\nwith \\(x_i\\) the coordinate of the node associated with the \\(i-\\)th shape function.\nSuch mapping can be expressed using the area coordinates \\(a_1\\) and \\(a_2\\) (such that \\(N_1\\left(\\xi\\right) = a_1\\) and \\(N_2\\left(\\xi\\right) = a_2\\)).\n\\(\\begin{pmatrix}\nx \\\\\n1\n\\end{pmatrix} = \\underbrace{\\begin{bmatrix}\nx_1 & x_2\\\\\n1 & 1\n\\end{bmatrix}}_{\\mathcal{M}} \\begin{pmatrix}\na_1 \\\\\na_2\n\\end{pmatrix}.\\)\nReciprocally (for non degenerated elements),\n\\(\\begin{pmatrix}\na_1 \\\\\na_2\n\\end{pmatrix} = \\underbrace{\\frac{1}{x_1 - x_2}\\begin{bmatrix}\n1 & -x_2\\\\\n-1 & x_1\n\\end{bmatrix}}_{\\mathcal{M}^{-1}} \\begin{pmatrix}\nx \\\\\n1\n\\end{pmatrix}.\\)",
    "crumbs": [
      "{{< iconify fa6-solid:rocket width=17 title=HAL >}}",
      "1D NeuROM",
      "L-BFGS"
    ]
  },
  {
    "objectID": "demos/1D_element_based_LBFGS.html#mesh-generation",
    "href": "demos/1D_element_based_LBFGS.html#mesh-generation",
    "title": "Element based 1D HideNN-FEM - L-BFGS training",
    "section": "",
    "text": "Code\nN           = 40\nnodes       = torch.linspace(0,6.28,N)\nnodes       = nodes[:,None]\nelements    = torch.vstack([torch.arange(0,N-1),torch.arange(1,N)]).T",
    "crumbs": [
      "{{< iconify fa6-solid:rocket width=17 title=HAL >}}",
      "1D NeuROM",
      "L-BFGS"
    ]
  },
  {
    "objectID": "demos/1D_element_based_LBFGS.html#assembly-using-the-vectorised-element-block",
    "href": "demos/1D_element_based_LBFGS.html#assembly-using-the-vectorised-element-block",
    "title": "Element based 1D HideNN-FEM - L-BFGS training",
    "section": "",
    "text": "Code\nclass interpolation1D(nn.Module):    \n    def __init__(self, \n            nodes           : torch.Tensor  = None  , \n            elements        : list          = None  , \n            dirichlet       : list          =[0,nodes.shape[0]-1]     ,                 # Fixed nodes (by default, 2 extremities of the beam)\n            n_components    : int           = 1     ):                                  # Number of dofs per node \n        super().__init__()        \n        self.register_buffer('nodes', nodes)\n        self.coordinates =nn.ParameterDict({\n                                    'all': self.nodes,\n                                    })                                                  # Should use different entries for trainable and fixed coordinates\n\n        \n        self.coordinates[\"all\"].requires_grad   = False \n        self.n_components                       = n_components\n        self.register_buffer('values',0.5*torch.ones((self.coordinates[\"all\"].shape[0], self.n_components)))\n        self.dirichlet = dirichlet\n\n        \n        self.elements = elements\n\n        self.Ne = len(elements)\n\n        self.shape_functions = mySF1D_elementBased_vectorised(elements)                 \n\n        # To easily transfer to CUDA or change dtype of whole model\n        self.register_buffer('one', torch.tensor([1], dtype=torch.float32))\n\n        self.SetBCs()\n\n    def SetBCs(self):\n        assert self.n_components == 1, \"only scalar field implemented. Aborting\"\n        if self.n_components == 1:\n            self.dofs_free                  = (torch.ones_like(self.values[:])==1)[:,0]\n            self.dofs_free[self.dirichlet]  = False\n            \n\n\n            nodal_values_imposed            = 0*self.values[~self.dofs_free,:]              # Not generic yet, only 0 BCs\n\n\n            nodal_values_free               = self.values[self.dofs_free,:] \n            self.nodal_values               = nn.ParameterDict({\n                                                'free'      : nodal_values_free,\n                                                'imposed'   : nodal_values_imposed,\n                                                })\n            self.nodal_values['imposed'].requires_grad = False\n\n    def forward(self, x = None): \n        if self.training :\n            k_elt = torch.arange(0,self.Ne)\n        else :\n            k_elt = []\n            for xx in x:\n                for k in range(self.Ne):\n                    elt = self.elements[k]\n                    if xx &gt;= self.coordinates[\"all\"][elt[0]] and xx &lt;= self.coordinates[\"all\"][elt[1]]:\n                        k_elt.append(k)\n                        break\n        if self.training : \n            shape_functions, x_g, detJ = self.shape_functions(\n                x               = x                 , \n                cell_id         = k_elt             , \n                coordinates     = self.nodes        , \n                flag_training   = self.training     )\n        else:\n            shape_functions = self.shape_functions(\n                x               = x                 , \n                cell_id         = k_elt             , \n                coordinates     = self.nodes        , \n                flag_training   = self.training     )\n        # Batch interpolation of the solution using the computed shape functions batch\n        nodal_values_tensor                     = torch.ones_like(self.values)\n        nodal_values_tensor[self.dofs_free,:]   = self.nodal_values['free']\n        nodal_values_tensor[~self.dofs_free,:]  = self.nodal_values['imposed']                    \n\n        cell_nodes_IDs      = self.elements[k_elt,:].T\n        Ids                 = torch.as_tensor(cell_nodes_IDs).to(nodal_values_tensor.device).t()[:,:,None]      # :,:,None] usefull only in 2+D  \n\n        \n        self.nodes_values   = torch.gather(nodal_values_tensor[:,None,:].repeat(1,2,1),0, Ids.repeat(1,1,1))    # [:,:,None] usefull only in 2+D  Ids.repeat(1,1,d) with d \\in [1,3]\n        self.nodes_values   = self.nodes_values.to(shape_functions.dtype)\n        u = torch.einsum('gi...,gi-&gt;g',self.nodes_values,shape_functions)   \n\n        if self.training : \n\n            return u, x_g, detJ\n        else:\n            return u\n\n\n\n\nCode\nmodel = interpolation1D(nodes, elements)\nmodel.train()\nprint(\"* Model set in training mode\")\n\n\n* Model set in training mode",
    "crumbs": [
      "{{< iconify fa6-solid:rocket width=17 title=HAL >}}",
      "1D NeuROM",
      "L-BFGS"
    ]
  },
  {
    "objectID": "demos/1D_element_based_LBFGS.html#training-with-batch-version",
    "href": "demos/1D_element_based_LBFGS.html#training-with-batch-version",
    "title": "Element based 1D HideNN-FEM - L-BFGS training",
    "section": "",
    "text": "Code\ndef PotentialEnergy(u,x,f,J):\n    \"\"\"Computes the potential energy of the Beam, which will be used as the loss of the HiDeNN\"\"\"\n    du_dx = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n    # Vectorised calculation of the integral terms\n    int_term1 =  0.5 * du_dx*du_dx * J\n    int_term2 =  f(x) * J * u\n\n    # Vectorised calculation of the integral using the trapezoidal rule\n    integral = torch.sum(int_term1 - int_term2)\n    return integral\n\ndef f(x):\n    return 1000 #-x*(x-10)\n\n\n\n\nCode\n\noptimizer = torch.optim.LBFGS(model.parameters(),\n                line_search_fn=\"strong_wolfe\")\n# Training\nNepoch          = 10\nlossList        = []\nlossTraining    = []\n\ndef closure():\n    optimizer.zero_grad()\n    u, x_g, detJ    = model()\n    loss            = PotentialEnergy(u,x_g,f,detJ)\n    loss.backward()\n    return loss\n\nmodel.train()\nfor i in range(Nepoch):\n    optimizer.step(closure)\n    loss = closure()\n    lossTraining.append(loss.data)\n    print(f\"{i = } | loss = {loss.data :.2e}\", end = \"\\r\")\n\n\ni = 9 | loss = -4.02e+08\n\n\n\n\n\n\nCode\nimport matplotlib.pyplot as plt\n\n# plt.figure()\n# plt.plot(lossTraining)\n# plt.xlabel(\"Epochs\")\n# plt.ylabel(\"Loss\")\n# plt.show()\n\n\n\nfig = go.Figure()\n\n\nfig.add_trace(go.Scatter( y=lossTraining, mode='lines+markers', name='du/dx', line=dict(color='#01426a')\n))\n\nfig.update_layout(\n    margin=dict(l=0, r=0, t=0, b=0),\n    plot_bgcolor='rgba(0,0,0,0)',  # Remove background color\n    width=700, \n    height=400,  \n    xaxis=dict(title='Epochs',\n    showgrid=True,\n    gridcolor='lightgray'),\n    yaxis=dict(title='Loss',\n    tickvals=[-4.022e8, -4.016e8, -4.008e8],\n    ticktext=['-4.022e8', '-4.016e8', '-4.008e8'],\n    showgrid=True,\n    gridcolor='lightgray',\n    titlefont=dict(color='#01426a'),\n    tickfont=dict(color='#01426a'),),\n)\n\nfig.show()\n\n\n                                                \n\n\n\n\nCode\nmodel.train()\n\nu, x_g, detJ    = model()\n\nmodel.eval()\n\nx_test = torch.linspace(0,6,30)\nu_eval = model(x_test)\n# plt.figure()\n# plt.plot(x_g.data,u.data, '+',label='Gauss points')\n# plt.plot(x_test.data,u_eval.data, 'o',label='Test points')\n# plt.xlabel(\"x [mm]\")\n# plt.ylabel(\"u(x) [mm]\")\n# plt.legend()\n# plt.show() \n\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=x_g.data[:,0], y=u.data, mode='markers', marker=dict(symbol='cross'), name='Gauss points',    line=dict(color='#01426a')))\n\nfig.add_trace(go.Scatter(x=x_test.data, y=u_eval.data, mode='markers', marker=dict(symbol='circle'), name='Test points', line=dict(color='#CE0037')))\n\nfig.update_layout(\n    margin=dict(l=0, r=0, t=0, b=0),\n    plot_bgcolor='rgba(0,0,0,0)',  # Remove background color\n    width=700, \n    height=400,  \n    xaxis=dict(title='x [mm]',\n    showgrid=True,\n    gridcolor='lightgray'),\n    yaxis=dict(title='u(x) [mm]',\n    showgrid=True,\n    gridcolor='lightgray',\n    titlefont=dict(color='#01426a'),\n    tickfont=dict(color='#01426a'),),    \n    legend=dict(x=0, y=1, traceorder=\"normal\")\n)\n\nfig.show()\n\n\n                                                \n\n\n\n\nCode\nmodel.train()\nu, x_g, detJ    = model()\ndu_dxg = torch.autograd.grad(u, x_g, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n# plt.figure()\n# plt.plot(x_g.data,du_dxg.data, '-o')\n# plt.xlabel(\"x [mm]\")\n# plt.ylabel(\"du/dx [mm/mm]\")\n# plt.show()\n\nfig = go.Figure()\n\nx_data = x_g.data.numpy()[:,0]\ny_data = du_dxg.data.numpy()[:,0]\nfig.add_trace(go.Scatter(x=x_data, y=y_data, mode='lines+markers', name='du/dx', line=dict(color='#01426a')\n))\n\nfig.update_layout(\n    margin=dict(l=0, r=0, t=0, b=0),\n    plot_bgcolor='rgba(0,0,0,0)',  # Remove background color\n    width=700, \n    height=400,  \n    xaxis=dict(title='x [mm]',\n    showgrid=True,\n    gridcolor='lightgray'),\n    yaxis=dict(title='du/dx [mm/mm]',\n    showgrid=True,\n    gridcolor='lightgray',\n    titlefont=dict(color='#01426a'),\n    tickfont=dict(color='#01426a'),),\n)\n\n\nfig.show()",
    "crumbs": [
      "{{< iconify fa6-solid:rocket width=17 title=HAL >}}",
      "1D NeuROM",
      "L-BFGS"
    ]
  }
]